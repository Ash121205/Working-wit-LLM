{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "baokDPaGV_4Y"
      },
      "outputs": [],
      "source": [
        "!pip -q install langchain openai tiktoken chromadb pypdf sentence_transformers InstructorEmbedding"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\""
      ],
      "metadata": {
        "id": "KbcSnVvjDlvI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.document_loaders import DirectoryLoader\n",
        "\n",
        "from InstructorEmbedding import INSTRUCTOR\n",
        "from langchain.embeddings import HuggingFaceInstructEmbeddings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckFeSIA9DxiE",
        "outputId": "98588165-e710-43f4-933a-e9e3f62083d8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/InstructorEmbedding/instructor.py:7: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import trange\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loader = DirectoryLoader('./files/', glob=\"./*.pdf\", loader_cls = PyPDFLoader)\n",
        "documents = loader.load()"
      ],
      "metadata": {
        "id": "HvYSZL3QEF5O"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
        "\n",
        "instructor_embeddings = HuggingFaceInstructEmbeddings(model_name=\"hkunlp/instructor-xl\",\n",
        "                                                       model_kwargs={\"device\":\"cuda\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPgiGKxC6v2f",
        "outputId": "26049c2b-318c-4e57-aeca-cc04e9755bb3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load INSTRUCTOR_Transformer\n",
            "max_seq_length  512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "texts = text_splitter.split_documents(documents)"
      ],
      "metadata": {
        "id": "CO8yRkMcFAS5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CKWB1-KFVfY",
        "outputId": "2a68cd27-89fd-4be9-ad08-d65acbefd21a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "persist_directory = 'db'\n",
        "\n",
        "embeddings = instructor_embeddings\n",
        "\n",
        "vectordb = Chroma.from_documents(texts,\n",
        "                                 embedding = embeddings)"
      ],
      "metadata": {
        "id": "Hpbh8SKlFXpQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectordb.as_retriever(search_kwargs={'k':10})"
      ],
      "metadata": {
        "id": "UTm9UUkTG87z"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"\n",
        "From the given input,\n",
        "Give me all the rows containing \"gwp\" and format them in json format where the key is the product name along with the parameters and value is the numerical value of the respective product in product stage module along with the unit.\n",
        "\"\"\"\n",
        "docs = retriever.get_relevant_documents(query)"
      ],
      "metadata": {
        "id": "lS7e1WFgGgav"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(docs)"
      ],
      "metadata": {
        "id": "bhPIeOjXG69N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69d435ed-ce65-44d0-e652-90476a0b7dc4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever.search_type"
      ],
      "metadata": {
        "id": "3lqWv_xLHMjh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "c2bd0214-d940-4e2c-ec1f-890e36a64083"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'similarity'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever.search_kwargs"
      ],
      "metadata": {
        "id": "0QUS1JZcHQmi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ea98322-1e26-4c15-d4e0-da286660dba0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'k': 10}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "turbo = ChatOpenAI(temperature=0, model_name = \"gpt-3.5-turbo\")"
      ],
      "metadata": {
        "id": "5k37myyWJoTr"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_chain = RetrievalQA.from_chain_type(llm=turbo,\n",
        "                                      chain_type='stuff',\n",
        "                                      retriever=retriever,\n",
        "                                      return_source_documents=True)"
      ],
      "metadata": {
        "id": "1OFbN7X6HTLF"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "def wrap_text_preserve_newlines(text, width=110):\n",
        "  #split the input text into lines\n",
        "  lines = text.split(\"\\n\")\n",
        "\n",
        "  #Wrap each line individually\n",
        "  wrapped_lines = [textwrap.fil(line, width=width) for line in lines]\n",
        "\n",
        "  #Join the wrapped lines back together\n",
        "  wrapped_text = '\\n'.join(wrapped_lines)\n",
        "\n",
        "  return wrapped_text"
      ],
      "metadata": {
        "id": "XBKF4QRW72AA"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_llm_response(llm_response):\n",
        "  print(llm_response['result'])\n",
        "  print('\\n\\n Sources:')\n",
        "  for source in llm_response['source_documents']:\n",
        "    print(source.metadata['source'])"
      ],
      "metadata": {
        "id": "_CbEmBLdHjZu"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"\n",
        "From the given input,\n",
        "Give me all the rows containing \"gwp\" and format them in json format where the key is the product name along with the parameters and value is the numerical value of the respective product in product stage module along with the unit.\n",
        "\"\"\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ],
      "metadata": {
        "id": "Tu_ppAtaIP5n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c529abfb-51d4-48c5-d4df-3aceb5875ce7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"Hollow Structural Sections (HSS)\": {\n",
            "    \"Climate Change - total\": \"1701.06 kg CO2 eq.\",\n",
            "    \"Climate Change - fossil\": \"1697.74 kg CO2 eq.\",\n",
            "    \"Climate Change - biogenic\": \"2.85 kg CO2 eq.\",\n",
            "    \"Climate Change - LULUC\": \"0.46 kg CO2 eq.\",\n",
            "    \"GWP -GHG\": \"1698.21 kg CO2 eq.\"\n",
            "  }\n",
            "}\n",
            "\n",
            "\n",
            " Sources:\n",
            "files/Data_2.pdf\n",
            "files/Data_2.pdf\n",
            "files/Data_2.pdf\n",
            "files/Data_2.pdf\n",
            "files/Data_2.pdf\n",
            "files/Data_2.pdf\n",
            "files/Data_2.pdf\n",
            "files/Data_2.pdf\n",
            "files/Data_2.pdf\n",
            "files/Data_2.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oteP87ZzpXNi"
      },
      "execution_count": 18,
      "outputs": []
    }
  ]
}